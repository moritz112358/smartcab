{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Smartcab Project Report ***\n",
    "==============================\n",
    "\n",
    "by Moritz Bendiek\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a basic driving agent\n",
    "-------------------------------\n",
    "\n",
    "The requested behavior (random choice of action disregarding any input information) is realized by adding the following code to the `update` method:\n",
    "\n",
    "`action_list = [None, 'forward', 'left', 'right']`\n",
    "\n",
    "`action = action_list[random.randint(0,3)]`\n",
    "\n",
    "Note that `random` should be initialized (via `seed`) first.\n",
    "\n",
    "**Question:** Observe what you see with the agent's behavior as it takes random actions. Does the **smartcab** eventually make it to the destination? Are there any other interesting observations to note?\n",
    "\n",
    "**Answer**: The agent executes a \"random walk\". Due to the limited size of the world model (6*8=48 positions on the grid), the smartcab will arrive at its destination within a reasonably short time span. I executed 100 test runs and found that the smartcab arrived at the destination before the hard time limit (-100) was reached 63 times, and 37 times the agent ran into the hard time limit.\n",
    "\n",
    "The smartcab apparently is influenced by the traffic lights, insofar as it does not always move when it sees a \"red\" light. However, judging from the visualization, I am not sure that this behavior is consistent. Also, the movement of the smartcab somedoes does not seem to fit to the chosen action (e.g. displays 'left' as action, but drives forward). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inform the driving agent\n",
    "------------------------\n",
    "\n",
    "**QUESTION:** What states have you identified that are appropriate for modeling the smartcab and environment? Why do you believe each of these states to be appropriate for this problem?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**OPTIONAL:** How many states in total exist for the smartcab in this environment? Does this number seem reasonable given that the goal of Q-Learning is to learn and make informed decisions about each state? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a Q-Learning Driving Agent\n",
    "------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improve the Q-Learning Driving Agent\n",
    "------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
